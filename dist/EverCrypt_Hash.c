/* 
  This file was generated by KaRaMeL <https://github.com/FStarLang/karamel>
  KaRaMeL invocation: /home/gebner/everest/karamel/krml /home/gebner/everest/merkle-tree/obj/FStar_Pervasives_Native.krml /home/gebner/everest/merkle-tree/obj/FStar_Pervasives.krml /home/gebner/everest/merkle-tree/obj/FStar_Float.krml /home/gebner/everest/merkle-tree/obj/FStar_Mul.krml /home/gebner/everest/merkle-tree/obj/FStar_Squash.krml /home/gebner/everest/merkle-tree/obj/FStar_Classical.krml /home/gebner/everest/merkle-tree/obj/FStar_Preorder.krml /home/gebner/everest/merkle-tree/obj/FStar_Sealed.krml /home/gebner/everest/merkle-tree/obj/FStar_Range.krml /home/gebner/everest/merkle-tree/obj/FStar_Calc.krml /home/gebner/everest/merkle-tree/obj/FStar_StrongExcludedMiddle.krml /home/gebner/everest/merkle-tree/obj/FStar_Classical_Sugar.krml /home/gebner/everest/merkle-tree/obj/FStar_List_Tot_Base.krml /home/gebner/everest/merkle-tree/obj/FStar_List_Tot_Properties.krml /home/gebner/everest/merkle-tree/obj/FStar_List_Tot.krml /home/gebner/everest/merkle-tree/obj/FStar_Seq_Base.krml /home/gebner/everest/merkle-tree/obj/FStar_Seq_Properties.krml /home/gebner/everest/merkle-tree/obj/FStar_Seq.krml /home/gebner/everest/merkle-tree/obj/FStar_Math_Lib.krml /home/gebner/everest/merkle-tree/obj/FStar_Math_Lemmas.krml /home/gebner/everest/merkle-tree/obj/FStar_BitVector.krml /home/gebner/everest/merkle-tree/obj/FStar_UInt.krml /home/gebner/everest/merkle-tree/obj/FStar_UInt32.krml /home/gebner/everest/merkle-tree/obj/FStar_Char.krml /home/gebner/everest/merkle-tree/obj/FStar_Pprint.krml /home/gebner/everest/merkle-tree/obj/FStar_Issue.krml /home/gebner/everest/merkle-tree/obj/FStar_TypeChecker_Core.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Common.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_Types.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Types.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Result.krml /home/gebner/everest/merkle-tree/obj/FStar_Monotonic_Pure.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Effect.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Unseal.krml /home/gebner/everest/merkle-tree/obj/FStar_VConfig.krml /home/gebner/everest/merkle-tree/obj/FStar_Sealed_Inhabited.krml /home/gebner/everest/merkle-tree/obj/FStar_Syntax_Syntax.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V2_Data.krml /home/gebner/everest/merkle-tree/obj/FStar_Order.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V2_Builtins.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_Const.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V2_Builtins.krml /home/gebner/everest/merkle-tree/obj/FStar_FunctionalExtensionality.krml /home/gebner/everest/merkle-tree/obj/FStar_Set.krml /home/gebner/everest/merkle-tree/obj/FStar_Map.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_Set.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_Meta.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_Words_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_Words_Two_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_Seqs_s.krml /home/gebner/everest/merkle-tree/obj/FStar_UInt8.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_Words_Four_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_Words_Seq_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_Opaque_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_Types_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_Words_Two.krml /home/gebner/everest/merkle-tree/obj/FStar_Exn.krml /home/gebner/everest/merkle-tree/obj/FStar_Monotonic_Witnessed.krml /home/gebner/everest/merkle-tree/obj/FStar_Ghost.krml /home/gebner/everest/merkle-tree/obj/FStar_ErasedLogic.krml /home/gebner/everest/merkle-tree/obj/FStar_PropositionalExtensionality.krml /home/gebner/everest/merkle-tree/obj/FStar_PredicateExtensionality.krml /home/gebner/everest/merkle-tree/obj/FStar_TSet.krml /home/gebner/everest/merkle-tree/obj/FStar_Monotonic_Heap.krml /home/gebner/everest/merkle-tree/obj/FStar_Heap.krml /home/gebner/everest/merkle-tree/obj/FStar_ST.krml /home/gebner/everest/merkle-tree/obj/FStar_All.krml /home/gebner/everest/merkle-tree/obj/FStar_List.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_Seqs.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_TypesNative_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Arch_TypesNative.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_Words_Seq.krml /home/gebner/everest/merkle-tree/obj/Vale_Arch_Types.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_Prop_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Arch_MachineHeap_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Arch_MachineHeap.krml /home/gebner/everest/merkle-tree/obj/FStar_Option.krml /home/gebner/everest/merkle-tree/obj/FStar_Monotonic_HyperHeap.krml /home/gebner/everest/merkle-tree/obj/FStar_Monotonic_HyperStack.krml /home/gebner/everest/merkle-tree/obj/FStar_HyperStack.krml /home/gebner/everest/merkle-tree/obj/FStar_HyperStack_ST.krml /home/gebner/everest/merkle-tree/obj/FStar_Universe.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_SMT.krml /home/gebner/everest/merkle-tree/obj/FStar_GSet.krml /home/gebner/everest/merkle-tree/obj/FStar_ModifiesGen.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Util.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V2_Derived.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V2_Compare.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V2_Derived_Lemmas.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V2.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_NamedView.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V1_Data.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V1_Builtins.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V1_Builtins.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Builtins.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V2_SyntaxCoercions.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Visit.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V2_SyntaxHelpers.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V2_Formula.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V2_Derived.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Typeclasses.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_MApply.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Print.krml /home/gebner/everest/merkle-tree/obj/FStar_IndefiniteDescription.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V2_Logic.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V2.krml /home/gebner/everest/merkle-tree/obj/FStar_BigOps.krml /home/gebner/everest/merkle-tree/obj/LowStar_Monotonic_Buffer.krml /home/gebner/everest/merkle-tree/obj/LowStar_Buffer.krml /home/gebner/everest/merkle-tree/obj/LowStar_Modifies.krml /home/gebner/everest/merkle-tree/obj/LowStar_BufferView_Down.krml /home/gebner/everest/merkle-tree/obj/FStar_UInt64.krml /home/gebner/everest/merkle-tree/obj/FStar_UInt16.krml /home/gebner/everest/merkle-tree/obj/LowStar_BufferView_Up.krml /home/gebner/everest/merkle-tree/obj/Vale_Interop_Views.krml /home/gebner/everest/merkle-tree/obj/LowStar_ImmutableBuffer.krml /home/gebner/everest/merkle-tree/obj/Vale_Arch_HeapTypes_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Interop_Types.krml /home/gebner/everest/merkle-tree/obj/Vale_Interop_Heap_s.krml /home/gebner/everest/merkle-tree/obj/LowStar_ModifiesPat.krml /home/gebner/everest/merkle-tree/obj/LowStar_BufferView.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_BufferViewHelpers.krml /home/gebner/everest/merkle-tree/obj/Vale_Interop.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Machine_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_Map16.krml /home/gebner/everest/merkle-tree/obj/Vale_Arch_HeapImpl.krml /home/gebner/everest/merkle-tree/obj/Vale_Arch_Heap.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Instruction_s.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Bytes_Code_s.krml /home/gebner/everest/merkle-tree/obj/Vale_AES_AES_common_s.krml /home/gebner/everest/merkle-tree/obj/Vale_AES_AES_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Math_Poly2_Defs_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Math_Poly2_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Math_Poly2_Bits_s.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V1_Derived.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V1_Formula.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V1_Compare.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V1_Derived_Lemmas.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V1.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V1_SyntaxHelpers.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V1_Derived.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V1_Logic.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_V1.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics.krml /home/gebner/everest/merkle-tree/obj/Lib_LoopCombinators.krml /home/gebner/everest/merkle-tree/obj/FStar_Int.krml /home/gebner/everest/merkle-tree/obj/FStar_Int64.krml /home/gebner/everest/merkle-tree/obj/FStar_Int32.krml /home/gebner/everest/merkle-tree/obj/FStar_Int16.krml /home/gebner/everest/merkle-tree/obj/FStar_Int8.krml /home/gebner/everest/merkle-tree/obj/FStar_Int_Cast.krml /home/gebner/everest/merkle-tree/obj/FStar_BV.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_V2_Arith.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_BV.krml /home/gebner/everest/merkle-tree/obj/FStar_UInt128.krml /home/gebner/everest/merkle-tree/obj/FStar_Int_Cast_Full.krml /home/gebner/everest/merkle-tree/obj/FStar_Int128.krml /home/gebner/everest/merkle-tree/obj/Lib_IntTypes.krml /home/gebner/everest/merkle-tree/obj/Lib_Sequence.krml /home/gebner/everest/merkle-tree/obj/Spec_Loops.krml /home/gebner/everest/merkle-tree/obj/Lib_UpdateMulti.krml /home/gebner/everest/merkle-tree/obj/Lib_RawIntTypes.krml /home/gebner/everest/merkle-tree/obj/Lib_ByteSequence.krml /home/gebner/everest/merkle-tree/obj/Spec_Blake2.krml /home/gebner/everest/merkle-tree/obj/Spec_Hash_Definitions.krml /home/gebner/everest/merkle-tree/obj/Spec_SHA2_Constants.krml /home/gebner/everest/merkle-tree/obj/Spec_SHA2.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_CryptoInstructions_s.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_CPU_Features_s.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Instructions_s.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Machine_Semantics_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Interop_Base.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Memory.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Stack_i.krml /home/gebner/everest/merkle-tree/obj/Lib_Sequence_Lemmas.krml /home/gebner/everest/merkle-tree/obj/Lib_Memzero0.krml /home/gebner/everest/merkle-tree/obj/LowStar_BufferOps.krml /home/gebner/everest/merkle-tree/obj/C_Loops.krml /home/gebner/everest/merkle-tree/obj/Lib_Loops.krml /home/gebner/everest/merkle-tree/obj/LowStar_ConstBuffer.krml /home/gebner/everest/merkle-tree/obj/Lib_Buffer.krml /home/gebner/everest/merkle-tree/obj/FStar_Endianness.krml /home/gebner/everest/merkle-tree/obj/LowStar_Endianness.krml /home/gebner/everest/merkle-tree/obj/Lib_ByteBuffer.krml /home/gebner/everest/merkle-tree/obj/FStar_HyperStack_All.krml /home/gebner/everest/merkle-tree/obj/Lib_IntVector_Intrinsics.krml /home/gebner/everest/merkle-tree/obj/Spec_GaloisField.krml /home/gebner/everest/merkle-tree/obj/Spec_AES.krml /home/gebner/everest/merkle-tree/obj/Lib_IntVector.krml /home/gebner/everest/merkle-tree/obj/Lib_IntVector_Serialize.krml /home/gebner/everest/merkle-tree/obj/Hacl_Impl_SHA2_Types.krml /home/gebner/everest/merkle-tree/obj/Spec_SHA3_Constants.krml /home/gebner/everest/merkle-tree/obj/Spec_SHA3.krml /home/gebner/everest/merkle-tree/obj/Spec_SHA1.krml /home/gebner/everest/merkle-tree/obj/Spec_MD5.krml /home/gebner/everest/merkle-tree/obj/Spec_Hash_MD.krml /home/gebner/everest/merkle-tree/obj/Spec_Agile_Hash.krml /home/gebner/everest/merkle-tree/obj/Spec_Hash_Lemmas.krml /home/gebner/everest/merkle-tree/obj/Spec_Hash_Incremental_Definitions.krml /home/gebner/everest/merkle-tree/obj/Spec_MD_Incremental.krml /home/gebner/everest/merkle-tree/obj/Spec_SHA3_Incremental.krml /home/gebner/everest/merkle-tree/obj/Spec_Blake2_Alternative.krml /home/gebner/everest/merkle-tree/obj/Spec_Blake2_Incremental.krml /home/gebner/everest/merkle-tree/obj/Spec_Hash_Incremental.krml /home/gebner/everest/merkle-tree/obj/Hacl_Impl_Blake2_Core.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_Definitions.krml /home/gebner/everest/merkle-tree/obj/Lib_IntVector_Transpose.krml /home/gebner/everest/merkle-tree/obj/Hacl_Spec_SHA2.krml /home/gebner/everest/merkle-tree/obj/Lib_NTuple.krml /home/gebner/everest/merkle-tree/obj/Hacl_Spec_SHA2_Vec.krml /home/gebner/everest/merkle-tree/obj/Lib_MultiBuffer.krml /home/gebner/everest/merkle-tree/obj/Hacl_Impl_SHA2_Core.krml /home/gebner/everest/merkle-tree/obj/Lib_Vec_Lemmas.krml /home/gebner/everest/merkle-tree/obj/Lib_UpdateMulti_Lemmas.krml /home/gebner/everest/merkle-tree/obj/Hacl_Spec_SHA2_EquivScalar.krml /home/gebner/everest/merkle-tree/obj/Hacl_Spec_SHA2_Lemmas.krml /home/gebner/everest/merkle-tree/obj/Hacl_Spec_SHA2_Equiv.krml /home/gebner/everest/merkle-tree/obj/Spec_SHA2_Lemmas.krml /home/gebner/everest/merkle-tree/obj/Hacl_SHA2_Scalar32_Lemmas.krml /home/gebner/everest/merkle-tree/obj/Hacl_Impl_SHA2_Generic.krml /home/gebner/everest/merkle-tree/obj/Hacl_SHA2_Scalar32.krml /home/gebner/everest/merkle-tree/obj/FStar_IO.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_BufferViewStore.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Memory_Sems.krml /home/gebner/everest/merkle-tree/obj/Vale_Def_PossiblyMonad.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Flags.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Stack_Sems.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Regs.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_State.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_StateLemmas.krml /home/gebner/everest/merkle-tree/obj/Vale_Arch_HeapLemmas.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Lemmas.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Print_s.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Decls.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_MemoryAdapters.krml /home/gebner/everest/merkle-tree/obj/Vale_Interop_Assumptions.krml /home/gebner/everest/merkle-tree/obj/Vale_Interop_X64.krml /home/gebner/everest/merkle-tree/obj/Vale_AsLowStar_ValeSig.krml /home/gebner/everest/merkle-tree/obj/Vale_AsLowStar_LowStarSig.krml /home/gebner/everest/merkle-tree/obj/Vale_AsLowStar_MemoryHelpers.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_QuickCode.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_QuickCodes.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Taint_Semantics.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_InsLemmas.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_InsBasic.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_InsMem.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_InsVector.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_InsStack.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_Stack.krml /home/gebner/everest/merkle-tree/obj/Vale_SHA_SHA_helpers.krml /home/gebner/everest/merkle-tree/obj/Vale_X64_InsSha.krml /home/gebner/everest/merkle-tree/obj/Vale_SHA_X64.krml /home/gebner/everest/merkle-tree/obj/Vale_AsLowStar_Wrapper.krml /home/gebner/everest/merkle-tree/obj/Vale_Stdcalls_X64_Sha.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_Bv_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Math_Bits.krml /home/gebner/everest/merkle-tree/obj/FStar_Reflection_Formula.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Derived.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_Tactics.krml /home/gebner/everest/merkle-tree/obj/Vale_Poly1305_Bitvectors.krml /home/gebner/everest/merkle-tree/obj/FStar_Algebra_CommMonoid.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_CanonCommSemiring.krml /home/gebner/everest/merkle-tree/obj/Vale_Math_Lemmas_Int.krml /home/gebner/everest/merkle-tree/obj/FStar_Tactics_Canon.krml /home/gebner/everest/merkle-tree/obj/Vale_Poly1305_Spec_s.krml /home/gebner/everest/merkle-tree/obj/Vale_Poly1305_Math.krml /home/gebner/everest/merkle-tree/obj/Vale_Poly1305_Util.krml /home/gebner/everest/merkle-tree/obj/Vale_Poly1305_X64.krml /home/gebner/everest/merkle-tree/obj/Vale_Stdcalls_X64_Poly.krml /home/gebner/everest/merkle-tree/obj/Vale_Wrapper_X64_Poly.krml /home/gebner/everest/merkle-tree/obj/Vale_Arch_BufferFriend.krml /home/gebner/everest/merkle-tree/obj/Vale_SHA_Simplify_Sha.krml /home/gebner/everest/merkle-tree/obj/Vale_Wrapper_X64_Sha.krml /home/gebner/everest/merkle-tree/obj/LowStar_Ignore.krml /home/gebner/everest/merkle-tree/obj/Hacl_Impl_Blake2_Constants.krml /home/gebner/everest/merkle-tree/obj/Hacl_Impl_Blake2_Generic.krml /home/gebner/everest/merkle-tree/obj/Hacl_Blake2s_128.krml /home/gebner/everest/merkle-tree/obj/Hacl_Blake2s_32.krml /home/gebner/everest/merkle-tree/obj/Hacl_Blake2b_256.krml /home/gebner/everest/merkle-tree/obj/Hacl_Blake2b_32.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_Blake2.krml /home/gebner/everest/merkle-tree/obj/Spec_SHA3_Equivalence.krml /home/gebner/everest/merkle-tree/obj/Hacl_Impl_SHA3.krml /home/gebner/everest/merkle-tree/obj/Hacl_SHA3.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_Lemmas.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_PadFinish.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_SHA3.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_MD.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_SHA2.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_Core_SHA1.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_SHA1.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_Core_MD5.krml /home/gebner/everest/merkle-tree/obj/Hacl_Hash_MD5.krml /home/gebner/everest/merkle-tree/obj/EverCrypt_TargetConfig.krml /home/gebner/everest/merkle-tree/obj/C.krml /home/gebner/everest/merkle-tree/obj/FStar_String.krml /home/gebner/everest/merkle-tree/obj/C_String.krml /home/gebner/everest/merkle-tree/obj/C_Failure.krml /home/gebner/everest/merkle-tree/obj/FStar_Integers.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_Basic.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_X64_Cpuid.krml /home/gebner/everest/merkle-tree/obj/Vale_Lib_X64_Cpuidstdcall.krml /home/gebner/everest/merkle-tree/obj/Vale_Stdcalls_X64_Cpuid.krml /home/gebner/everest/merkle-tree/obj/Vale_Wrapper_X64_Cpuid.krml /home/gebner/everest/merkle-tree/obj/EverCrypt_AutoConfig2.krml /home/gebner/everest/merkle-tree/obj/EverCrypt_Helpers.krml /home/gebner/everest/merkle-tree/obj/EverCrypt_Hash.krml /home/gebner/everest/merkle-tree/obj/LowStar_Vector.krml /home/gebner/everest/merkle-tree/obj/LowStar_Regional.krml /home/gebner/everest/merkle-tree/obj/LowStar_RVector.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_Spec.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_New_High.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_New_High_Correct_Base.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_New_High_Correct_Rhs.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_New_High_Correct_Path.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_New_High_Correct_Flushing.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_New_High_Correct_Insertion.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_New_High_Correct.krml /home/gebner/everest/merkle-tree/obj/LowStar_Regional_Instances.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_Low_Datastructures.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_Low_Hashfunctions.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_Low_VectorExtras.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_Low.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_EverCrypt.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_Init.krml /home/gebner/everest/merkle-tree/obj/Lib_RawBuffer.krml /home/gebner/everest/merkle-tree/obj/MerkleTree_Low_Serialization.krml /home/gebner/everest/merkle-tree/obj/MerkleTree.krml -tmpdir dist -skip-compilation -minimal -add-include "krml/internal/target.h" -add-include "krml/internal/types.h" -add-include "krml/lowstar_endianness.h" -add-include <stdint.h> -add-include <stdbool.h> -add-include <string.h> -fparentheses -o libmerkletree.a -library Vale.Stdcalls.* -no-prefix Vale.Stdcalls.* -static-header Vale.Inline.* -library Vale.Inline.X64.Fadd_inline -library Vale.Inline.X64.Fmul_inline -library Vale.Inline.X64.Fswap_inline -library Vale.Inline.X64.Fsqr_inline -no-prefix Vale.Inline.X64.Fadd_inline -no-prefix Vale.Inline.X64.Fmul_inline -no-prefix Vale.Inline.X64.Fswap_inline -no-prefix Vale.Inline.X64.Fsqr_inline -no-prefix MerkleTree -no-prefix MerkleTree.EverCrypt -bundle EverCrypt.Hash=EverCrypt,EverCrypt.*,Meta.*,Hacl.*,Vale.*,Spec.*,Lib.* -library EverCrypt.AutoConfig2 -bundle MerkleTree+MerkleTree.Init+MerkleTree.EverCrypt+MerkleTree.Low+MerkleTree.Low.Serialization+MerkleTree.Low.Hashfunctions=MerkleTree.*[rename=MerkleTree] -bundle LowStar.* -bundle Prims,C.Failure,C,C.String,C.Loops,Spec.Loops,C.Endianness,FStar.*[rename=Merkle_Krmllib] -library Meta.*,Hacl.*,Vale.*,Spec.*,Lib.* -ccopts -DLib_IntVector_Intrinsics_vec256=void*,-DLib_IntVector_Intrinsics_vec128=void*
  F* version: 67747003
  KaRaMeL version: a7be2a7c
 */

#include "internal/EverCrypt_Hash.h"

#include "internal/Merkle_Krmllib.h"

extern Lib_IntVector_Intrinsics_vec128 Lib_IntVector_Intrinsics_vec128_zero;

extern Lib_IntVector_Intrinsics_vec256 Lib_IntVector_Intrinsics_vec256_zero;

extern void Hacl_SHA2_Scalar32_sha256_init(uint32_t *hash);

extern void Hacl_SHA2_Scalar32_sha256_update_nblocks(uint32_t len, uint8_t *b, uint32_t *st);

extern void
Hacl_SHA2_Scalar32_sha256_update_last(
  uint64_t totlen,
  uint32_t len,
  uint8_t *b,
  uint32_t *hash
);

extern void Hacl_SHA2_Scalar32_sha256_finish(uint32_t *st, uint8_t *h);

extern void Hacl_SHA2_Scalar32_sha224_init(uint32_t *hash);

extern void
Hacl_SHA2_Scalar32_sha224_update_last(uint64_t totlen, uint32_t len, uint8_t *b, uint32_t *st);

extern void Hacl_SHA2_Scalar32_sha224_finish(uint32_t *st, uint8_t *h);

extern void Hacl_SHA2_Scalar32_sha512_init(uint64_t *hash);

extern void Hacl_SHA2_Scalar32_sha512_update_nblocks(uint32_t len, uint8_t *b, uint64_t *st);

extern void
Hacl_SHA2_Scalar32_sha512_update_last(
  FStar_UInt128_uint128 totlen,
  uint32_t len,
  uint8_t *b,
  uint64_t *hash
);

extern void Hacl_SHA2_Scalar32_sha512_finish(uint64_t *st, uint8_t *h);

extern void Hacl_SHA2_Scalar32_sha384_init(uint64_t *hash);

extern void Hacl_SHA2_Scalar32_sha384_update_nblocks(uint32_t len, uint8_t *b, uint64_t *st);

extern void
Hacl_SHA2_Scalar32_sha384_update_last(
  FStar_UInt128_uint128 totlen,
  uint32_t len,
  uint8_t *b,
  uint64_t *st
);

extern void Hacl_SHA2_Scalar32_sha384_finish(uint64_t *st, uint8_t *h);

typedef uint64_t als_ret;

extern uint64_t sha256_update(uint32_t *x0, uint8_t *x1, uint64_t x2, uint32_t *x3);

extern void
Hacl_Blake2s_128_blake2s_init(Lib_IntVector_Intrinsics_vec128 *hash, uint32_t kk, uint32_t nn);

extern void
Hacl_Blake2s_128_blake2s_update_multi(
  uint32_t len,
  Lib_IntVector_Intrinsics_vec128 *wv,
  Lib_IntVector_Intrinsics_vec128 *hash,
  uint64_t prev,
  uint8_t *blocks,
  uint32_t nb
);

extern void
Hacl_Blake2s_128_blake2s_update_last(
  uint32_t len,
  Lib_IntVector_Intrinsics_vec128 *wv,
  Lib_IntVector_Intrinsics_vec128 *hash,
  uint64_t prev,
  uint32_t rem,
  uint8_t *d
);

extern void
Hacl_Blake2s_128_blake2s_finish(
  uint32_t nn,
  uint8_t *output,
  Lib_IntVector_Intrinsics_vec128 *hash
);

extern void
Hacl_Blake2s_128_store_state128s_to_state32(
  uint32_t *st32,
  Lib_IntVector_Intrinsics_vec128 *st
);

extern void
Hacl_Blake2s_128_load_state128s_from_state32(
  Lib_IntVector_Intrinsics_vec128 *st,
  uint32_t *st32
);

extern Lib_IntVector_Intrinsics_vec128 *Hacl_Blake2s_128_blake2s_malloc(void);

extern void Hacl_Blake2s_32_blake2s_init(uint32_t *hash, uint32_t kk, uint32_t nn);

extern void
Hacl_Blake2s_32_blake2s_update_multi(
  uint32_t len,
  uint32_t *wv,
  uint32_t *hash,
  uint64_t prev,
  uint8_t *blocks,
  uint32_t nb
);

extern void
Hacl_Blake2s_32_blake2s_update_last(
  uint32_t len,
  uint32_t *wv,
  uint32_t *hash,
  uint64_t prev,
  uint32_t rem,
  uint8_t *d
);

extern void Hacl_Blake2s_32_blake2s_finish(uint32_t nn, uint8_t *output, uint32_t *hash);

extern void
Hacl_Blake2b_256_blake2b_init(Lib_IntVector_Intrinsics_vec256 *hash, uint32_t kk, uint32_t nn);

extern void
Hacl_Blake2b_256_blake2b_update_multi(
  uint32_t len,
  Lib_IntVector_Intrinsics_vec256 *wv,
  Lib_IntVector_Intrinsics_vec256 *hash,
  FStar_UInt128_uint128 prev,
  uint8_t *blocks,
  uint32_t nb
);

extern void
Hacl_Blake2b_256_blake2b_update_last(
  uint32_t len,
  Lib_IntVector_Intrinsics_vec256 *wv,
  Lib_IntVector_Intrinsics_vec256 *hash,
  FStar_UInt128_uint128 prev,
  uint32_t rem,
  uint8_t *d
);

extern void
Hacl_Blake2b_256_blake2b_finish(
  uint32_t nn,
  uint8_t *output,
  Lib_IntVector_Intrinsics_vec256 *hash
);

extern void
Hacl_Blake2b_256_load_state256b_from_state32(
  Lib_IntVector_Intrinsics_vec256 *st,
  uint64_t *st32
);

extern void
Hacl_Blake2b_256_store_state256b_to_state32(
  uint64_t *st32,
  Lib_IntVector_Intrinsics_vec256 *st
);

extern Lib_IntVector_Intrinsics_vec256 *Hacl_Blake2b_256_blake2b_malloc(void);

extern void Hacl_Blake2b_32_blake2b_init(uint64_t *hash, uint32_t kk, uint32_t nn);

extern void
Hacl_Blake2b_32_blake2b_update_multi(
  uint32_t len,
  uint64_t *wv,
  uint64_t *hash,
  FStar_UInt128_uint128 prev,
  uint8_t *blocks,
  uint32_t nb
);

extern void
Hacl_Blake2b_32_blake2b_update_last(
  uint32_t len,
  uint64_t *wv,
  uint64_t *hash,
  FStar_UInt128_uint128 prev,
  uint32_t rem,
  uint8_t *d
);

extern void Hacl_Blake2b_32_blake2b_finish(uint32_t nn, uint8_t *output, uint64_t *hash);

extern void
Hacl_Impl_SHA3_squeeze(
  uint64_t *s,
  uint32_t rateInBytes,
  uint32_t outputByteLen,
  uint8_t *output
);

extern void
Hacl_Hash_SHA3_update_multi_sha3(
  Spec_Hash_Definitions_hash_alg a,
  uint64_t *s,
  uint8_t *blocks,
  uint32_t n_blocks
);

extern void
Hacl_Hash_SHA3_update_last_sha3(
  Spec_Hash_Definitions_hash_alg a,
  uint64_t *s,
  uint8_t *input,
  uint32_t input_len
);

extern void Hacl_Hash_Core_SHA1_legacy_init(uint32_t *s);

extern void Hacl_Hash_Core_SHA1_legacy_finish(uint32_t *s, uint8_t *dst);

extern void
Hacl_Hash_SHA1_legacy_update_multi(uint32_t *s, uint8_t *blocks, uint32_t n_blocks);

extern void
Hacl_Hash_SHA1_legacy_update_last(
  uint32_t *s,
  uint64_t prev_len,
  uint8_t *input,
  uint32_t input_len
);

extern void Hacl_Hash_Core_MD5_legacy_init(uint32_t *s);

extern void Hacl_Hash_Core_MD5_legacy_finish(uint32_t *s, uint8_t *dst);

extern void Hacl_Hash_MD5_legacy_update_multi(uint32_t *s, uint8_t *blocks, uint32_t n_blocks);

extern void
Hacl_Hash_MD5_legacy_update_last(
  uint32_t *s,
  uint64_t prev_len,
  uint8_t *input,
  uint32_t input_len
);

extern bool EverCrypt_AutoConfig2_has_shaext(void);

extern bool EverCrypt_AutoConfig2_has_sse(void);

extern bool EverCrypt_AutoConfig2_has_vec128(void);

extern bool EverCrypt_AutoConfig2_has_vec256(void);

Prims_string EverCrypt_Hash_string_of_alg(Spec_Hash_Definitions_hash_alg uu___)
{
  switch (uu___)
  {
    case Spec_Hash_Definitions_MD5:
      {
        return "MD5";
      }
    case Spec_Hash_Definitions_SHA1:
      {
        return "SHA1";
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        return "SHA2_224";
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        return "SHA2_256";
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        return "SHA2_384";
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        return "SHA2_512";
      }
    case Spec_Hash_Definitions_SHA3_224:
      {
        return "SHA3_224";
      }
    case Spec_Hash_Definitions_SHA3_256:
      {
        return "SHA3_256";
      }
    case Spec_Hash_Definitions_SHA3_384:
      {
        return "SHA3_384";
      }
    case Spec_Hash_Definitions_SHA3_512:
      {
        return "SHA3_512";
      }
    case Spec_Hash_Definitions_Shake128:
      {
        return "Shake128";
      }
    case Spec_Hash_Definitions_Shake256:
      {
        return "Shake256";
      }
    case Spec_Hash_Definitions_Blake2S:
      {
        return "Blake2S";
      }
    case Spec_Hash_Definitions_Blake2B:
      {
        return "Blake2B";
      }
    default:
      {
        KRML_HOST_EPRINTF("KaRaMeL incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
}

#define MD5_s 0
#define SHA1_s 1
#define SHA2_224_s 2
#define SHA2_256_s 3
#define SHA2_384_s 4
#define SHA2_512_s 5
#define SHA3_224_s 6
#define SHA3_256_s 7
#define SHA3_384_s 8
#define SHA3_512_s 9
#define Blake2S_s 10
#define Blake2S_128_s 11
#define Blake2B_s 12
#define Blake2B_256_s 13

typedef uint8_t state_s_tags;

typedef struct EverCrypt_Hash_state_s_s
{
  state_s_tags tag;
  union {
    uint32_t *case_MD5_s;
    uint32_t *case_SHA1_s;
    uint32_t *case_SHA2_224_s;
    uint32_t *case_SHA2_256_s;
    uint64_t *case_SHA2_384_s;
    uint64_t *case_SHA2_512_s;
    uint64_t *case_SHA3_224_s;
    uint64_t *case_SHA3_256_s;
    uint64_t *case_SHA3_384_s;
    uint64_t *case_SHA3_512_s;
    uint32_t *case_Blake2S_s;
    Lib_IntVector_Intrinsics_vec128 *case_Blake2S_128_s;
    uint64_t *case_Blake2B_s;
    Lib_IntVector_Intrinsics_vec256 *case_Blake2B_256_s;
  }
  ;
}
EverCrypt_Hash_state_s;

bool
EverCrypt_Hash_uu___is_MD5_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == MD5_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_SHA1_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == SHA1_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_SHA2_224_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == SHA2_224_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_SHA2_256_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == SHA2_256_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_SHA2_384_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == SHA2_384_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_SHA2_512_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == SHA2_512_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_SHA3_224_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == SHA3_224_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_SHA3_256_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == SHA3_256_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_SHA3_384_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == SHA3_384_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_SHA3_512_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == SHA3_512_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_Blake2S_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == Blake2S_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_Blake2S_128_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == Blake2S_128_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_Blake2B_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == Blake2B_s)
    return true;
  else
    return false;
}

bool
EverCrypt_Hash_uu___is_Blake2B_256_s(
  Spec_Hash_Definitions_hash_alg uu___,
  EverCrypt_Hash_state_s projectee
)
{
  KRML_MAYBE_UNUSED_VAR(uu___);
  if (projectee.tag == Blake2B_256_s)
    return true;
  else
    return false;
}

Spec_Hash_Definitions_hash_alg EverCrypt_Hash_alg_of_state(EverCrypt_Hash_state_s *s)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == MD5_s)
    return Spec_Hash_Definitions_MD5;
  else if (scrut.tag == SHA1_s)
    return Spec_Hash_Definitions_SHA1;
  else if (scrut.tag == SHA2_224_s)
    return Spec_Hash_Definitions_SHA2_224;
  else if (scrut.tag == SHA2_256_s)
    return Spec_Hash_Definitions_SHA2_256;
  else if (scrut.tag == SHA2_384_s)
    return Spec_Hash_Definitions_SHA2_384;
  else if (scrut.tag == SHA2_512_s)
    return Spec_Hash_Definitions_SHA2_512;
  else if (scrut.tag == SHA3_224_s)
    return Spec_Hash_Definitions_SHA3_224;
  else if (scrut.tag == SHA3_256_s)
    return Spec_Hash_Definitions_SHA3_256;
  else if (scrut.tag == SHA3_384_s)
    return Spec_Hash_Definitions_SHA3_384;
  else if (scrut.tag == SHA3_512_s)
    return Spec_Hash_Definitions_SHA3_512;
  else if (scrut.tag == Blake2S_s)
    return Spec_Hash_Definitions_Blake2S;
  else if (scrut.tag == Blake2S_128_s)
    return Spec_Hash_Definitions_Blake2S;
  else if (scrut.tag == Blake2B_s)
    return Spec_Hash_Definitions_Blake2B;
  else if (scrut.tag == Blake2B_256_s)
    return Spec_Hash_Definitions_Blake2B;
  else
  {
    KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

EverCrypt_Hash_state_s *EverCrypt_Hash_create_in(Spec_Hash_Definitions_hash_alg a)
{
  EverCrypt_Hash_state_s s;
  switch (a)
  {
    case Spec_Hash_Definitions_MD5:
      {
        uint32_t *buf = KRML_HOST_CALLOC(4U, sizeof (uint32_t));
        s = ((EverCrypt_Hash_state_s){ .tag = MD5_s, { .case_MD5_s = buf } });
        break;
      }
    case Spec_Hash_Definitions_SHA1:
      {
        uint32_t *buf = KRML_HOST_CALLOC(5U, sizeof (uint32_t));
        s = ((EverCrypt_Hash_state_s){ .tag = SHA1_s, { .case_SHA1_s = buf } });
        break;
      }
    case Spec_Hash_Definitions_SHA2_224:
      {
        uint32_t *buf = KRML_HOST_CALLOC(8U, sizeof (uint32_t));
        s = ((EverCrypt_Hash_state_s){ .tag = SHA2_224_s, { .case_SHA2_224_s = buf } });
        break;
      }
    case Spec_Hash_Definitions_SHA2_256:
      {
        uint32_t *buf = KRML_HOST_CALLOC(8U, sizeof (uint32_t));
        s = ((EverCrypt_Hash_state_s){ .tag = SHA2_256_s, { .case_SHA2_256_s = buf } });
        break;
      }
    case Spec_Hash_Definitions_SHA2_384:
      {
        uint64_t *buf = KRML_HOST_CALLOC(8U, sizeof (uint64_t));
        s = ((EverCrypt_Hash_state_s){ .tag = SHA2_384_s, { .case_SHA2_384_s = buf } });
        break;
      }
    case Spec_Hash_Definitions_SHA2_512:
      {
        uint64_t *buf = KRML_HOST_CALLOC(8U, sizeof (uint64_t));
        s = ((EverCrypt_Hash_state_s){ .tag = SHA2_512_s, { .case_SHA2_512_s = buf } });
        break;
      }
    case Spec_Hash_Definitions_SHA3_224:
      {
        uint64_t *buf = KRML_HOST_CALLOC(25U, sizeof (uint64_t));
        s = ((EverCrypt_Hash_state_s){ .tag = SHA3_224_s, { .case_SHA3_224_s = buf } });
        break;
      }
    case Spec_Hash_Definitions_SHA3_256:
      {
        uint64_t *buf = KRML_HOST_CALLOC(25U, sizeof (uint64_t));
        s = ((EverCrypt_Hash_state_s){ .tag = SHA3_256_s, { .case_SHA3_256_s = buf } });
        break;
      }
    case Spec_Hash_Definitions_SHA3_384:
      {
        uint64_t *buf = KRML_HOST_CALLOC(25U, sizeof (uint64_t));
        s = ((EverCrypt_Hash_state_s){ .tag = SHA3_384_s, { .case_SHA3_384_s = buf } });
        break;
      }
    case Spec_Hash_Definitions_SHA3_512:
      {
        uint64_t *buf = KRML_HOST_CALLOC(25U, sizeof (uint64_t));
        s = ((EverCrypt_Hash_state_s){ .tag = SHA3_512_s, { .case_SHA3_512_s = buf } });
        break;
      }
    case Spec_Hash_Definitions_Blake2S:
      {
        #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC128
        bool vec128 = EverCrypt_AutoConfig2_has_vec128();
        if (vec128)
          s =
            (
              (EverCrypt_Hash_state_s){
                .tag = Blake2S_128_s,
                { .case_Blake2S_128_s = Hacl_Blake2s_128_blake2s_malloc() }
              }
            );
        else
        {
          uint32_t *buf = KRML_HOST_CALLOC(16U, sizeof (uint32_t));
          s = ((EverCrypt_Hash_state_s){ .tag = Blake2S_s, { .case_Blake2S_s = buf } });
        }
        #else
        uint32_t *buf = KRML_HOST_CALLOC(16U, sizeof (uint32_t));
        s = ((EverCrypt_Hash_state_s){ .tag = Blake2S_s, { .case_Blake2S_s = buf } });
        #endif
        break;
      }
    case Spec_Hash_Definitions_Blake2B:
      {
        #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC256
        bool vec256 = EverCrypt_AutoConfig2_has_vec256();
        if (vec256)
          s =
            (
              (EverCrypt_Hash_state_s){
                .tag = Blake2B_256_s,
                { .case_Blake2B_256_s = Hacl_Blake2b_256_blake2b_malloc() }
              }
            );
        else
        {
          uint64_t *buf = KRML_HOST_CALLOC(16U, sizeof (uint64_t));
          s = ((EverCrypt_Hash_state_s){ .tag = Blake2B_s, { .case_Blake2B_s = buf } });
        }
        #else
        uint64_t *buf = KRML_HOST_CALLOC(16U, sizeof (uint64_t));
        s = ((EverCrypt_Hash_state_s){ .tag = Blake2B_s, { .case_Blake2B_s = buf } });
        #endif
        break;
      }
    default:
      {
        KRML_HOST_EPRINTF("KaRaMeL incomplete match at %s:%d\n", __FILE__, __LINE__);
        KRML_HOST_EXIT(253U);
      }
  }
  EverCrypt_Hash_state_s *buf = KRML_HOST_MALLOC(sizeof (EverCrypt_Hash_state_s));
  buf[0U] = s;
  return buf;
}

EverCrypt_Hash_state_s *EverCrypt_Hash_create(Spec_Hash_Definitions_hash_alg a)
{
  return EverCrypt_Hash_create_in(a);
}

void EverCrypt_Hash_init(EverCrypt_Hash_state_s *s)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == MD5_s)
  {
    uint32_t *p1 = scrut.case_MD5_s;
    Hacl_Hash_Core_MD5_legacy_init(p1);
  }
  else if (scrut.tag == SHA1_s)
  {
    uint32_t *p1 = scrut.case_SHA1_s;
    Hacl_Hash_Core_SHA1_legacy_init(p1);
  }
  else if (scrut.tag == SHA2_224_s)
  {
    uint32_t *p1 = scrut.case_SHA2_224_s;
    Hacl_SHA2_Scalar32_sha224_init(p1);
  }
  else if (scrut.tag == SHA2_256_s)
  {
    uint32_t *p1 = scrut.case_SHA2_256_s;
    Hacl_SHA2_Scalar32_sha256_init(p1);
  }
  else if (scrut.tag == SHA2_384_s)
  {
    uint64_t *p1 = scrut.case_SHA2_384_s;
    Hacl_SHA2_Scalar32_sha384_init(p1);
  }
  else if (scrut.tag == SHA2_512_s)
  {
    uint64_t *p1 = scrut.case_SHA2_512_s;
    Hacl_SHA2_Scalar32_sha512_init(p1);
  }
  else if (scrut.tag == SHA3_224_s)
  {
    uint64_t *p1 = scrut.case_SHA3_224_s;
    memset(p1, 0U, 25U * sizeof (uint64_t));
  }
  else if (scrut.tag == SHA3_256_s)
  {
    uint64_t *p1 = scrut.case_SHA3_256_s;
    memset(p1, 0U, 25U * sizeof (uint64_t));
  }
  else if (scrut.tag == SHA3_384_s)
  {
    uint64_t *p1 = scrut.case_SHA3_384_s;
    memset(p1, 0U, 25U * sizeof (uint64_t));
  }
  else if (scrut.tag == SHA3_512_s)
  {
    uint64_t *p1 = scrut.case_SHA3_512_s;
    memset(p1, 0U, 25U * sizeof (uint64_t));
  }
  else if (scrut.tag == Blake2S_s)
  {
    uint32_t *p1 = scrut.case_Blake2S_s;
    Hacl_Blake2s_32_blake2s_init(p1, 0U, 32U);
  }
  else if (scrut.tag == Blake2S_128_s)
  {
    Lib_IntVector_Intrinsics_vec128 *p1 = scrut.case_Blake2S_128_s;
    #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC128
    Hacl_Blake2s_128_blake2s_init(p1, 0U, 32U);
    #else
    KRML_MAYBE_UNUSED_VAR(p1);
    #endif
  }
  else if (scrut.tag == Blake2B_s)
  {
    uint64_t *p1 = scrut.case_Blake2B_s;
    Hacl_Blake2b_32_blake2b_init(p1, 0U, 64U);
  }
  else if (scrut.tag == Blake2B_256_s)
  {
    Lib_IntVector_Intrinsics_vec256 *p1 = scrut.case_Blake2B_256_s;
    #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC256
    Hacl_Blake2b_256_blake2b_init(p1, 0U, 64U);
    #else
    KRML_MAYBE_UNUSED_VAR(p1);
    #endif
  }
  else
  {
    KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

static uint32_t
k224_256[64U] =
  {
    0x428a2f98U, 0x71374491U, 0xb5c0fbcfU, 0xe9b5dba5U, 0x3956c25bU, 0x59f111f1U, 0x923f82a4U,
    0xab1c5ed5U, 0xd807aa98U, 0x12835b01U, 0x243185beU, 0x550c7dc3U, 0x72be5d74U, 0x80deb1feU,
    0x9bdc06a7U, 0xc19bf174U, 0xe49b69c1U, 0xefbe4786U, 0x0fc19dc6U, 0x240ca1ccU, 0x2de92c6fU,
    0x4a7484aaU, 0x5cb0a9dcU, 0x76f988daU, 0x983e5152U, 0xa831c66dU, 0xb00327c8U, 0xbf597fc7U,
    0xc6e00bf3U, 0xd5a79147U, 0x06ca6351U, 0x14292967U, 0x27b70a85U, 0x2e1b2138U, 0x4d2c6dfcU,
    0x53380d13U, 0x650a7354U, 0x766a0abbU, 0x81c2c92eU, 0x92722c85U, 0xa2bfe8a1U, 0xa81a664bU,
    0xc24b8b70U, 0xc76c51a3U, 0xd192e819U, 0xd6990624U, 0xf40e3585U, 0x106aa070U, 0x19a4c116U,
    0x1e376c08U, 0x2748774cU, 0x34b0bcb5U, 0x391c0cb3U, 0x4ed8aa4aU, 0x5b9cca4fU, 0x682e6ff3U,
    0x748f82eeU, 0x78a5636fU, 0x84c87814U, 0x8cc70208U, 0x90befffaU, 0xa4506cebU, 0xbef9a3f7U,
    0xc67178f2U
  };

void EverCrypt_Hash_update_multi_256(uint32_t *s, uint8_t *blocks, uint32_t n)
{
  #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VALE
  bool has_shaext = EverCrypt_AutoConfig2_has_shaext();
  bool has_sse = EverCrypt_AutoConfig2_has_sse();
  if (has_shaext && has_sse)
  {
    uint64_t n1 = (uint64_t)n;
    sha256_update(s, blocks, n1, k224_256);
  }
  else
    Hacl_SHA2_Scalar32_sha256_update_nblocks(n * 64U, blocks, s);
  #else
  KRML_HOST_IGNORE(k224_256);
  Hacl_SHA2_Scalar32_sha256_update_nblocks(n * 64U, blocks, s);
  #endif
}

void
EverCrypt_Hash_update_multi(
  EverCrypt_Hash_state_s *s,
  uint64_t prevlen,
  uint8_t *blocks,
  uint32_t len
)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == MD5_s)
  {
    uint32_t *p1 = scrut.case_MD5_s;
    uint32_t n = len / 64U;
    Hacl_Hash_MD5_legacy_update_multi(p1, blocks, n);
  }
  else if (scrut.tag == SHA1_s)
  {
    uint32_t *p1 = scrut.case_SHA1_s;
    uint32_t n = len / 64U;
    Hacl_Hash_SHA1_legacy_update_multi(p1, blocks, n);
  }
  else if (scrut.tag == SHA2_224_s)
  {
    uint32_t *p1 = scrut.case_SHA2_224_s;
    uint32_t n = len / 64U;
    EverCrypt_Hash_update_multi_256(p1, blocks, n);
  }
  else if (scrut.tag == SHA2_256_s)
  {
    uint32_t *p1 = scrut.case_SHA2_256_s;
    uint32_t n = len / 64U;
    EverCrypt_Hash_update_multi_256(p1, blocks, n);
  }
  else if (scrut.tag == SHA2_384_s)
  {
    uint64_t *p1 = scrut.case_SHA2_384_s;
    uint32_t n = len / 128U;
    Hacl_SHA2_Scalar32_sha384_update_nblocks(n * 128U, blocks, p1);
  }
  else if (scrut.tag == SHA2_512_s)
  {
    uint64_t *p1 = scrut.case_SHA2_512_s;
    uint32_t n = len / 128U;
    Hacl_SHA2_Scalar32_sha512_update_nblocks(n * 128U, blocks, p1);
  }
  else if (scrut.tag == SHA3_224_s)
  {
    uint64_t *p1 = scrut.case_SHA3_224_s;
    uint32_t n = len / 144U;
    Hacl_Hash_SHA3_update_multi_sha3(Spec_Hash_Definitions_SHA3_224, p1, blocks, n);
  }
  else if (scrut.tag == SHA3_256_s)
  {
    uint64_t *p1 = scrut.case_SHA3_256_s;
    uint32_t n = len / 136U;
    Hacl_Hash_SHA3_update_multi_sha3(Spec_Hash_Definitions_SHA3_256, p1, blocks, n);
  }
  else if (scrut.tag == SHA3_384_s)
  {
    uint64_t *p1 = scrut.case_SHA3_384_s;
    uint32_t n = len / 104U;
    Hacl_Hash_SHA3_update_multi_sha3(Spec_Hash_Definitions_SHA3_384, p1, blocks, n);
  }
  else if (scrut.tag == SHA3_512_s)
  {
    uint64_t *p1 = scrut.case_SHA3_512_s;
    uint32_t n = len / 72U;
    Hacl_Hash_SHA3_update_multi_sha3(Spec_Hash_Definitions_SHA3_512, p1, blocks, n);
  }
  else if (scrut.tag == Blake2S_s)
  {
    uint32_t *p1 = scrut.case_Blake2S_s;
    uint32_t n = len / 64U;
    uint32_t wv[16U] = { 0U };
    Hacl_Blake2s_32_blake2s_update_multi(n * 64U, wv, p1, prevlen, blocks, n);
  }
  else if (scrut.tag == Blake2S_128_s)
  {
    Lib_IntVector_Intrinsics_vec128 *p1 = scrut.case_Blake2S_128_s;
    #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC128
    uint32_t n = len / 64U;
    KRML_PRE_ALIGN(16) Lib_IntVector_Intrinsics_vec128 wv[4U] KRML_POST_ALIGN(16) = { 0U };
    Hacl_Blake2s_128_blake2s_update_multi(n * 64U, wv, p1, prevlen, blocks, n);
    #else
    KRML_MAYBE_UNUSED_VAR(p1);
    #endif
  }
  else if (scrut.tag == Blake2B_s)
  {
    uint64_t *p1 = scrut.case_Blake2B_s;
    uint32_t n = len / 128U;
    uint64_t wv[16U] = { 0U };
    Hacl_Blake2b_32_blake2b_update_multi(n * 128U,
      wv,
      p1,
      FStar_UInt128_uint64_to_uint128(prevlen),
      blocks,
      n);
  }
  else if (scrut.tag == Blake2B_256_s)
  {
    Lib_IntVector_Intrinsics_vec256 *p1 = scrut.case_Blake2B_256_s;
    #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC256
    uint32_t n = len / 128U;
    KRML_PRE_ALIGN(32) Lib_IntVector_Intrinsics_vec256 wv[4U] KRML_POST_ALIGN(32) = { 0U };
    Hacl_Blake2b_256_blake2b_update_multi(n * 128U,
      wv,
      p1,
      FStar_UInt128_uint64_to_uint128(prevlen),
      blocks,
      n);
    #else
    KRML_MAYBE_UNUSED_VAR(p1);
    #endif
  }
  else
  {
    KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

void
EverCrypt_Hash_update_last(
  EverCrypt_Hash_state_s *s,
  uint64_t prev_len,
  uint8_t *last,
  uint32_t last_len
)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == MD5_s)
  {
    uint32_t *p1 = scrut.case_MD5_s;
    Hacl_Hash_MD5_legacy_update_last(p1, prev_len, last, last_len);
  }
  else if (scrut.tag == SHA1_s)
  {
    uint32_t *p1 = scrut.case_SHA1_s;
    Hacl_Hash_SHA1_legacy_update_last(p1, prev_len, last, last_len);
  }
  else if (scrut.tag == SHA2_224_s)
  {
    uint32_t *p1 = scrut.case_SHA2_224_s;
    Hacl_SHA2_Scalar32_sha224_update_last(prev_len + (uint64_t)last_len, last_len, last, p1);
  }
  else if (scrut.tag == SHA2_256_s)
  {
    uint32_t *p1 = scrut.case_SHA2_256_s;
    Hacl_SHA2_Scalar32_sha256_update_last(prev_len + (uint64_t)last_len, last_len, last, p1);
  }
  else if (scrut.tag == SHA2_384_s)
  {
    uint64_t *p1 = scrut.case_SHA2_384_s;
    Hacl_SHA2_Scalar32_sha384_update_last(FStar_UInt128_add(FStar_UInt128_uint64_to_uint128(prev_len),
        FStar_UInt128_uint64_to_uint128((uint64_t)last_len)),
      last_len,
      last,
      p1);
  }
  else if (scrut.tag == SHA2_512_s)
  {
    uint64_t *p1 = scrut.case_SHA2_512_s;
    Hacl_SHA2_Scalar32_sha512_update_last(FStar_UInt128_add(FStar_UInt128_uint64_to_uint128(prev_len),
        FStar_UInt128_uint64_to_uint128((uint64_t)last_len)),
      last_len,
      last,
      p1);
  }
  else if (scrut.tag == SHA3_224_s)
  {
    uint64_t *p1 = scrut.case_SHA3_224_s;
    Hacl_Hash_SHA3_update_last_sha3(Spec_Hash_Definitions_SHA3_224, p1, last, last_len);
  }
  else if (scrut.tag == SHA3_256_s)
  {
    uint64_t *p1 = scrut.case_SHA3_256_s;
    Hacl_Hash_SHA3_update_last_sha3(Spec_Hash_Definitions_SHA3_256, p1, last, last_len);
  }
  else if (scrut.tag == SHA3_384_s)
  {
    uint64_t *p1 = scrut.case_SHA3_384_s;
    Hacl_Hash_SHA3_update_last_sha3(Spec_Hash_Definitions_SHA3_384, p1, last, last_len);
  }
  else if (scrut.tag == SHA3_512_s)
  {
    uint64_t *p1 = scrut.case_SHA3_512_s;
    Hacl_Hash_SHA3_update_last_sha3(Spec_Hash_Definitions_SHA3_512, p1, last, last_len);
  }
  else if (scrut.tag == Blake2S_s)
  {
    uint32_t *p1 = scrut.case_Blake2S_s;
    uint32_t wv[16U] = { 0U };
    Hacl_Blake2s_32_blake2s_update_last(last_len, wv, p1, prev_len, last_len, last);
  }
  else if (scrut.tag == Blake2S_128_s)
  {
    Lib_IntVector_Intrinsics_vec128 *p1 = scrut.case_Blake2S_128_s;
    #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC128
    KRML_PRE_ALIGN(16) Lib_IntVector_Intrinsics_vec128 wv[4U] KRML_POST_ALIGN(16) = { 0U };
    Hacl_Blake2s_128_blake2s_update_last(last_len, wv, p1, prev_len, last_len, last);
    #else
    KRML_MAYBE_UNUSED_VAR(p1);
    #endif
  }
  else if (scrut.tag == Blake2B_s)
  {
    uint64_t *p1 = scrut.case_Blake2B_s;
    uint64_t wv[16U] = { 0U };
    Hacl_Blake2b_32_blake2b_update_last(last_len,
      wv,
      p1,
      FStar_UInt128_uint64_to_uint128(prev_len),
      last_len,
      last);
  }
  else if (scrut.tag == Blake2B_256_s)
  {
    Lib_IntVector_Intrinsics_vec256 *p1 = scrut.case_Blake2B_256_s;
    #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC256
    KRML_PRE_ALIGN(32) Lib_IntVector_Intrinsics_vec256 wv[4U] KRML_POST_ALIGN(32) = { 0U };
    Hacl_Blake2b_256_blake2b_update_last(last_len,
      wv,
      p1,
      FStar_UInt128_uint64_to_uint128(prev_len),
      last_len,
      last);
    #else
    KRML_MAYBE_UNUSED_VAR(p1);
    #endif
  }
  else
  {
    KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

void EverCrypt_Hash_finish(EverCrypt_Hash_state_s *s, uint8_t *dst)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == MD5_s)
  {
    uint32_t *p1 = scrut.case_MD5_s;
    Hacl_Hash_Core_MD5_legacy_finish(p1, dst);
  }
  else if (scrut.tag == SHA1_s)
  {
    uint32_t *p1 = scrut.case_SHA1_s;
    Hacl_Hash_Core_SHA1_legacy_finish(p1, dst);
  }
  else if (scrut.tag == SHA2_224_s)
  {
    uint32_t *p1 = scrut.case_SHA2_224_s;
    Hacl_SHA2_Scalar32_sha224_finish(p1, dst);
  }
  else if (scrut.tag == SHA2_256_s)
  {
    uint32_t *p1 = scrut.case_SHA2_256_s;
    Hacl_SHA2_Scalar32_sha256_finish(p1, dst);
  }
  else if (scrut.tag == SHA2_384_s)
  {
    uint64_t *p1 = scrut.case_SHA2_384_s;
    Hacl_SHA2_Scalar32_sha384_finish(p1, dst);
  }
  else if (scrut.tag == SHA2_512_s)
  {
    uint64_t *p1 = scrut.case_SHA2_512_s;
    Hacl_SHA2_Scalar32_sha512_finish(p1, dst);
  }
  else if (scrut.tag == SHA3_224_s)
  {
    uint64_t *p1 = scrut.case_SHA3_224_s;
    Hacl_Impl_SHA3_squeeze(p1, 144U, 28U, dst);
  }
  else if (scrut.tag == SHA3_256_s)
  {
    uint64_t *p1 = scrut.case_SHA3_256_s;
    Hacl_Impl_SHA3_squeeze(p1, 136U, 32U, dst);
  }
  else if (scrut.tag == SHA3_384_s)
  {
    uint64_t *p1 = scrut.case_SHA3_384_s;
    Hacl_Impl_SHA3_squeeze(p1, 104U, 48U, dst);
  }
  else if (scrut.tag == SHA3_512_s)
  {
    uint64_t *p1 = scrut.case_SHA3_512_s;
    Hacl_Impl_SHA3_squeeze(p1, 72U, 64U, dst);
  }
  else if (scrut.tag == Blake2S_s)
  {
    uint32_t *p1 = scrut.case_Blake2S_s;
    Hacl_Blake2s_32_blake2s_finish(32U, dst, p1);
  }
  else if (scrut.tag == Blake2S_128_s)
  {
    Lib_IntVector_Intrinsics_vec128 *p1 = scrut.case_Blake2S_128_s;
    #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC128
    Hacl_Blake2s_128_blake2s_finish(32U, dst, p1);
    #else
    KRML_MAYBE_UNUSED_VAR(p1);
    #endif
  }
  else if (scrut.tag == Blake2B_s)
  {
    uint64_t *p1 = scrut.case_Blake2B_s;
    Hacl_Blake2b_32_blake2b_finish(64U, dst, p1);
  }
  else if (scrut.tag == Blake2B_256_s)
  {
    Lib_IntVector_Intrinsics_vec256 *p1 = scrut.case_Blake2B_256_s;
    #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC256
    Hacl_Blake2b_256_blake2b_finish(64U, dst, p1);
    #else
    KRML_MAYBE_UNUSED_VAR(p1);
    #endif
  }
  else
  {
    KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

void EverCrypt_Hash_free_(EverCrypt_Hash_state_s *s)
{
  EverCrypt_Hash_state_s scrut = *s;
  if (scrut.tag == MD5_s)
  {
    uint32_t *p1 = scrut.case_MD5_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == SHA1_s)
  {
    uint32_t *p1 = scrut.case_SHA1_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == SHA2_224_s)
  {
    uint32_t *p1 = scrut.case_SHA2_224_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == SHA2_256_s)
  {
    uint32_t *p1 = scrut.case_SHA2_256_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == SHA2_384_s)
  {
    uint64_t *p1 = scrut.case_SHA2_384_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == SHA2_512_s)
  {
    uint64_t *p1 = scrut.case_SHA2_512_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == SHA3_224_s)
  {
    uint64_t *p1 = scrut.case_SHA3_224_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == SHA3_256_s)
  {
    uint64_t *p1 = scrut.case_SHA3_256_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == SHA3_384_s)
  {
    uint64_t *p1 = scrut.case_SHA3_384_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == SHA3_512_s)
  {
    uint64_t *p1 = scrut.case_SHA3_512_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == Blake2S_s)
  {
    uint32_t *p1 = scrut.case_Blake2S_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == Blake2S_128_s)
  {
    Lib_IntVector_Intrinsics_vec128 *p1 = scrut.case_Blake2S_128_s;
    KRML_ALIGNED_FREE(p1);
  }
  else if (scrut.tag == Blake2B_s)
  {
    uint64_t *p1 = scrut.case_Blake2B_s;
    KRML_HOST_FREE(p1);
  }
  else if (scrut.tag == Blake2B_256_s)
  {
    Lib_IntVector_Intrinsics_vec256 *p1 = scrut.case_Blake2B_256_s;
    KRML_ALIGNED_FREE(p1);
  }
  else
  {
    KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
  KRML_HOST_FREE(s);
}

void EverCrypt_Hash_copy(EverCrypt_Hash_state_s *s_src, EverCrypt_Hash_state_s *s_dst)
{
  EverCrypt_Hash_state_s scrut0 = *s_src;
  if (scrut0.tag == MD5_s)
  {
    uint32_t *p_src = scrut0.case_MD5_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint32_t *p_dst;
    if (x1.tag == MD5_s)
      p_dst = x1.case_MD5_s;
    else
      p_dst = KRML_EABORT(uint32_t *, "unreachable (pattern matches are exhaustive in F*)");
    memcpy(p_dst, p_src, 4U * sizeof (uint32_t));
  }
  else if (scrut0.tag == SHA1_s)
  {
    uint32_t *p_src = scrut0.case_SHA1_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint32_t *p_dst;
    if (x1.tag == SHA1_s)
      p_dst = x1.case_SHA1_s;
    else
      p_dst = KRML_EABORT(uint32_t *, "unreachable (pattern matches are exhaustive in F*)");
    memcpy(p_dst, p_src, 5U * sizeof (uint32_t));
  }
  else if (scrut0.tag == SHA2_224_s)
  {
    uint32_t *p_src = scrut0.case_SHA2_224_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint32_t *p_dst;
    if (x1.tag == SHA2_224_s)
      p_dst = x1.case_SHA2_224_s;
    else
      p_dst = KRML_EABORT(uint32_t *, "unreachable (pattern matches are exhaustive in F*)");
    memcpy(p_dst, p_src, 8U * sizeof (uint32_t));
  }
  else if (scrut0.tag == SHA2_256_s)
  {
    uint32_t *p_src = scrut0.case_SHA2_256_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint32_t *p_dst;
    if (x1.tag == SHA2_256_s)
      p_dst = x1.case_SHA2_256_s;
    else
      p_dst = KRML_EABORT(uint32_t *, "unreachable (pattern matches are exhaustive in F*)");
    memcpy(p_dst, p_src, 8U * sizeof (uint32_t));
  }
  else if (scrut0.tag == SHA2_384_s)
  {
    uint64_t *p_src = scrut0.case_SHA2_384_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint64_t *p_dst;
    if (x1.tag == SHA2_384_s)
      p_dst = x1.case_SHA2_384_s;
    else
      p_dst = KRML_EABORT(uint64_t *, "unreachable (pattern matches are exhaustive in F*)");
    memcpy(p_dst, p_src, 8U * sizeof (uint64_t));
  }
  else if (scrut0.tag == SHA2_512_s)
  {
    uint64_t *p_src = scrut0.case_SHA2_512_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint64_t *p_dst;
    if (x1.tag == SHA2_512_s)
      p_dst = x1.case_SHA2_512_s;
    else
      p_dst = KRML_EABORT(uint64_t *, "unreachable (pattern matches are exhaustive in F*)");
    memcpy(p_dst, p_src, 8U * sizeof (uint64_t));
  }
  else if (scrut0.tag == SHA3_224_s)
  {
    uint64_t *p_src = scrut0.case_SHA3_224_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint64_t *p_dst;
    if (x1.tag == SHA3_224_s)
      p_dst = x1.case_SHA3_224_s;
    else
      p_dst = KRML_EABORT(uint64_t *, "unreachable (pattern matches are exhaustive in F*)");
    memcpy(p_dst, p_src, 25U * sizeof (uint64_t));
  }
  else if (scrut0.tag == SHA3_256_s)
  {
    uint64_t *p_src = scrut0.case_SHA3_256_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint64_t *p_dst;
    if (x1.tag == SHA3_256_s)
      p_dst = x1.case_SHA3_256_s;
    else
      p_dst = KRML_EABORT(uint64_t *, "unreachable (pattern matches are exhaustive in F*)");
    memcpy(p_dst, p_src, 25U * sizeof (uint64_t));
  }
  else if (scrut0.tag == SHA3_384_s)
  {
    uint64_t *p_src = scrut0.case_SHA3_384_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint64_t *p_dst;
    if (x1.tag == SHA3_384_s)
      p_dst = x1.case_SHA3_384_s;
    else
      p_dst = KRML_EABORT(uint64_t *, "unreachable (pattern matches are exhaustive in F*)");
    memcpy(p_dst, p_src, 25U * sizeof (uint64_t));
  }
  else if (scrut0.tag == SHA3_512_s)
  {
    uint64_t *p_src = scrut0.case_SHA3_512_s;
    EverCrypt_Hash_state_s x1 = *s_dst;
    uint64_t *p_dst;
    if (x1.tag == SHA3_512_s)
      p_dst = x1.case_SHA3_512_s;
    else
      p_dst = KRML_EABORT(uint64_t *, "unreachable (pattern matches are exhaustive in F*)");
    memcpy(p_dst, p_src, 25U * sizeof (uint64_t));
  }
  else if (scrut0.tag == Blake2S_s)
  {
    uint32_t *p_src = scrut0.case_Blake2S_s;
    EverCrypt_Hash_state_s scrut = *s_dst;
    if (scrut.tag == Blake2S_s)
    {
      uint32_t *p_dst = scrut.case_Blake2S_s;
      memcpy(p_dst, p_src, 16U * sizeof (uint32_t));
    }
    else if (scrut.tag == Blake2S_128_s)
    {
      Lib_IntVector_Intrinsics_vec128 *p_dst = scrut.case_Blake2S_128_s;
      #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC128
      Hacl_Blake2s_128_load_state128s_from_state32(p_dst, p_src);
      #else
      KRML_MAYBE_UNUSED_VAR(p_dst);
      #endif
    }
    else
    {
      KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
        __FILE__,
        __LINE__,
        "unreachable (pattern matches are exhaustive in F*)");
      KRML_HOST_EXIT(255U);
    }
  }
  else if (scrut0.tag == Blake2B_s)
  {
    uint64_t *p_src = scrut0.case_Blake2B_s;
    EverCrypt_Hash_state_s scrut = *s_dst;
    if (scrut.tag == Blake2B_s)
    {
      uint64_t *p_dst = scrut.case_Blake2B_s;
      memcpy(p_dst, p_src, 16U * sizeof (uint64_t));
    }
    else if (scrut.tag == Blake2B_256_s)
    {
      Lib_IntVector_Intrinsics_vec256 *p_dst = scrut.case_Blake2B_256_s;
      #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC256
      Hacl_Blake2b_256_load_state256b_from_state32(p_dst, p_src);
      #else
      KRML_MAYBE_UNUSED_VAR(p_dst);
      #endif
    }
    else
    {
      KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
        __FILE__,
        __LINE__,
        "unreachable (pattern matches are exhaustive in F*)");
      KRML_HOST_EXIT(255U);
    }
  }
  else if (scrut0.tag == Blake2S_128_s)
  {
    Lib_IntVector_Intrinsics_vec128 *p_src = scrut0.case_Blake2S_128_s;
    EverCrypt_Hash_state_s scrut = *s_dst;
    if (scrut.tag == Blake2S_128_s)
    {
      Lib_IntVector_Intrinsics_vec128 *p_dst = scrut.case_Blake2S_128_s;
      memcpy(p_dst, p_src, 4U * sizeof (Lib_IntVector_Intrinsics_vec128));
    }
    else if (scrut.tag == Blake2S_s)
    {
      uint32_t *p_dst = scrut.case_Blake2S_s;
      #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC128
      Hacl_Blake2s_128_store_state128s_to_state32(p_dst, p_src);
      #else
      KRML_MAYBE_UNUSED_VAR(p_dst);
      #endif
    }
    else
    {
      KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
        __FILE__,
        __LINE__,
        "unreachable (pattern matches are exhaustive in F*)");
      KRML_HOST_EXIT(255U);
    }
  }
  else if (scrut0.tag == Blake2B_256_s)
  {
    Lib_IntVector_Intrinsics_vec256 *p_src = scrut0.case_Blake2B_256_s;
    EverCrypt_Hash_state_s scrut = *s_dst;
    if (scrut.tag == Blake2B_256_s)
    {
      Lib_IntVector_Intrinsics_vec256 *p_dst = scrut.case_Blake2B_256_s;
      memcpy(p_dst, p_src, 4U * sizeof (Lib_IntVector_Intrinsics_vec256));
    }
    else if (scrut.tag == Blake2B_s)
    {
      uint64_t *p_dst = scrut.case_Blake2B_s;
      #if EVERCRYPT_TARGETCONFIG_HACL_CAN_COMPILE_VEC256
      Hacl_Blake2b_256_store_state256b_to_state32(p_dst, p_src);
      #else
      KRML_MAYBE_UNUSED_VAR(p_dst);
      #endif
    }
    else
    {
      KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
        __FILE__,
        __LINE__,
        "unreachable (pattern matches are exhaustive in F*)");
      KRML_HOST_EXIT(255U);
    }
  }
  else
  {
    KRML_HOST_EPRINTF("KaRaMeL abort at %s:%d\n%s\n",
      __FILE__,
      __LINE__,
      "unreachable (pattern matches are exhaustive in F*)");
    KRML_HOST_EXIT(255U);
  }
}

